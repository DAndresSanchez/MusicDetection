{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UnR3l6sTp1MW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5JzH7g_zmv8"
   },
   "outputs": [],
   "source": [
    "folder = '/home/daansan/David/MusicDetection/data2'\n",
    "\n",
    "# Load libraries\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.ndimage import convolve1d\n",
    "from scipy.io.wavfile import read, write\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G3lbSi6S15AW"
   },
   "outputs": [],
   "source": [
    "base_dir = '/tmp/music_and_voice'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with our training cat/dog pictures\n",
    "train_music_dir = os.path.join(train_dir, 'music')\n",
    "train_voice_dir = os.path.join(train_dir, 'voice')\n",
    "\n",
    "# Directory with our validation cat/dog pictures\n",
    "validation_music_dir = os.path.join(validation_dir, 'music')\n",
    "validation_voice_dir = os.path.join(validation_dir, 'voice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_jNmFpyxm3x"
   },
   "outputs": [],
   "source": [
    "dataset_path = folder\n",
    "json_path = \"data.json\"\n",
    "\n",
    "\n",
    "def save_chroma(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=25, segment_length = 0.5):\n",
    "\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"chroma\": []\n",
    "    }\n",
    "\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(folder)):\n",
    "            #print(dirpath)\n",
    "            # ensure we're processing a genre sub-folder level\n",
    "            #print(dataset_path)\n",
    "            if dirpath != dataset_path:\n",
    "                \n",
    "                # save genre label (i.e., sub-folder name) in the mapping\n",
    "                semantic_label = dirpath.split(\"/\")[-1]\n",
    "                if semantic_label[0] == '.':\n",
    "                  continue\n",
    "                \n",
    "                data['mapping'].append(semantic_label)\n",
    "                #print(\"\\nProcessing: {}\".format(semantic_label))\n",
    "\n",
    "                # process all audio files in genre sub-dir\n",
    "                for f in filenames:\n",
    "\n",
    "                    # load audio file\n",
    "                    file_path = os.path.join(dirpath, f)\n",
    "                    sr, signal = read(file_path)\n",
    "                    #signal, sr = librosa.load(file_path, sr=None)\n",
    "                    #signal = signal[:,1]\n",
    "\n",
    "                    y = signal[:,1].astype(np.float32)\n",
    "                    signal = y/np.abs(y).max()/2\n",
    "\n",
    "                    track_duration = signal.size/sr # measured in seconds\n",
    "                    num_segments = int(track_duration / segment_length)\n",
    "                    samples_per_track = sr * track_duration\n",
    "                    samples_per_segment = int(samples_per_track / num_segments)\n",
    "                    num_chroma_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "                    #print(f, track_duration, num_mfcc_vectors_per_segment)\n",
    "\n",
    "                    # process all segments of audio file\n",
    "                    for d in range(num_segments):\n",
    "\n",
    "                        # calculate start and finish sample for current segment\n",
    "                        start = samples_per_segment * d\n",
    "                        finish = start + samples_per_segment\n",
    "\n",
    "                        # extract chroma\n",
    "                        chroma = librosa.feature.chroma_cqt(y=signal[start:finish], sr=sr, hop_length=hop_length)\n",
    "                        #print(signal[start:finish].shape)\n",
    "\n",
    "\n",
    "                        ## extract mfcc\n",
    "                        #mfcc = librosa.feature.mfcc(signal[start:finish], sr, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "                        #mfcc = mfcc.T\n",
    "                        \n",
    "                        #print(chroma)\n",
    "                        \n",
    "\n",
    "\n",
    "                        data[\"chroma\"].append(chroma.tolist())\n",
    "                        data[\"labels\"].append(i-1)\n",
    "                        #print(\"{}, segment:{}\".format(file_path, d+1))\n",
    "\n",
    "    # save MFCCs to json file\n",
    "    # with open(json_path, \"w\") as fp:\n",
    "    #   json.dump(data, fp, indent=4)    \n",
    "    return data           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bc7LDAseyXyU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=698\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=349\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=175\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=784\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=392\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=196\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=711\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=356\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=178\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=728\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=364\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=182\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=743\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=372\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=186\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=706\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=353\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=177\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=708\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=354\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=695\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=348\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=174\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=710\n",
      "  n_fft, y.shape[-1]\n",
      "/home/daansan/David/MusicDetection/venv/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=355\n",
      "  n_fft, y.shape[-1]\n"
     ]
    }
   ],
   "source": [
    "data = save_chroma(dataset_path, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUdEEXbQIBnX"
   },
   "outputs": [],
   "source": [
    "with open(json_path, \"w\") as fp:\n",
    "       json.dump(np.array(data['chroma'][0]).tolist(), fp, indent=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USaldBD-FuTP"
   },
   "outputs": [],
   "source": [
    "data['chroma'][0] = np.array(data['chroma'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkP7K2Gqow_M"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_PATH = \"data.json\"\n",
    "\n",
    "def load_data_file(data):\n",
    "    \"\"\"Loads training dataset from json file.\n",
    "        :param data_path (str): Path to json file containing data\n",
    "        :return X (ndarray): Inputs\n",
    "        :return y (ndarray): Targets\n",
    "    \"\"\"\n",
    "\n",
    "    # with open(data_path, \"r\") as fp:\n",
    "    #     data = json.load(fp)\n",
    "\n",
    "    \n",
    "    for i in range(len(data['chroma'])):\n",
    "      data['chroma'][i] = np.array(data['chroma'][i])\n",
    "    X = data[\"chroma\"]\n",
    "    y = np.array(data[\"labels\"])\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# def load_data(data_path):\n",
    "#     \"\"\"Loads training dataset from json file.\n",
    "#         :param data_path (str): Path to json file containing data\n",
    "#         :return X (ndarray): Inputs\n",
    "#         :return y (ndarray): Targets\n",
    "#     \"\"\"\n",
    "\n",
    "#     with open(data_path, \"r\") as fp:\n",
    "#         data = json.load(fp)\n",
    "\n",
    "#     X = np.array(data[\"chroma\"])\n",
    "#     y = np.array(data[\"labels\"])\n",
    "#     return X, y\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n",
    "        :param history: Training history of model\n",
    "        :return:\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axs = plt.subplots(2)\n",
    "\n",
    "    # create accuracy sublpot\n",
    "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].set_title(\"Accuracy eval\")\n",
    "\n",
    "    # create error sublpot\n",
    "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
    "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
    "    axs[1].set_ylabel(\"Error\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Error eval\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def prepare_datasets(test_size, validation_size, data):\n",
    "    \"\"\"Loads data and splits it into train, validation and test sets.\n",
    "    :param test_size (float): Value in [0, 1] indicating percentage of data set to allocate to test split\n",
    "    :param validation_size (float): Value in [0, 1] indicating percentage of train set to allocate to validation split\n",
    "    :return X_train (ndarray): Input training set\n",
    "    :return X_validation (ndarray): Input validation set\n",
    "    :return X_test (ndarray): Input test set\n",
    "    :return y_train (ndarray): Target training set\n",
    "    :return y_validation (ndarray): Target validation set\n",
    "    :return y_test (ndarray): Target test set\n",
    "    \"\"\"\n",
    "\n",
    "    # load data\n",
    "    X, y = load_data_file(data)\n",
    "\n",
    "    # create train, validation and test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "\n",
    "    # add an axis to input sets\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_validation = X_validation[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "\n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test\n",
    "\n",
    "\n",
    "def build_model(input_shape):\n",
    "    \"\"\"Generates CNN model\n",
    "    :param input_shape (tuple): Shape of input set\n",
    "    :return model: CNN model\n",
    "    \"\"\"\n",
    "\n",
    "    # build network topology\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # 1st conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # flatten output and feed it into dense layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(model, X, y):\n",
    "    \"\"\"Predict a single sample using the trained model\n",
    "    :param model: Trained classifier\n",
    "    :param X: Input data\n",
    "    :param y (int): Target\n",
    "    \"\"\"\n",
    "\n",
    "    # add a dimension to input data for sample - model.predict() expects a 4d array in this case\n",
    "    X = X[np.newaxis, ...] # array shape (1, 130, 13, 1)\n",
    "\n",
    "    # perform prediction\n",
    "    prediction = model.predict(X)\n",
    "\n",
    "    # get index with max value\n",
    "    predicted_index = np.argmax(prediction, axis=1)\n",
    "\n",
    "    print(\"Target: {}, Predicted label: {}\".format(y, predicted_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "colab_type": "code",
    "id": "mouJoq0jow8I",
    "outputId": "cbd03256-f76c-4733-a15c-1ffd53e07808"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-240-77104bd97aa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get train, validation, test splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# create network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-239-9398d0428974>\u001b[0m in \u001b[0;36mprepare_datasets\u001b[0;34m(test_size, validation_size)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# create train, validation and test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-239-9398d0428974>\u001b[0m in \u001b[0;36mload_data_file\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \"\"\"\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_path' is not defined"
     ]
    }
   ],
   "source": [
    "# get train, validation, test splits\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2)\n",
    "\n",
    "# create network\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "model = build_model(input_shape)\n",
    "\n",
    "# compile model\n",
    "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimiser,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# train model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=30)\n",
    "\n",
    "# plot accuracy/error for training and validation\n",
    "plot_history(history)\n",
    "\n",
    "# evaluate model on test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# pick a sample to predict from the test set\n",
    "X_to_predict = X_test[100]\n",
    "y_to_predict = y_test[100]\n",
    "\n",
    "# predict sample\n",
    "predict(model, X_to_predict, y_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_M58_Afh4N-"
   },
   "outputs": [],
   "source": [
    "X, y = load_data_file(data)\n",
    "\n",
    "X[0] = np.hstack(X[0])\n",
    "\n",
    "# create train, validation and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.15)\n",
    "\n",
    "# add an axis to input sets\n",
    "# X_train = X_train[..., np.newaxis]\n",
    "# X_validation = X_validation[..., np.newaxis]\n",
    "# X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "F5e_qA1JiZHg",
    "outputId": "3a28b320-46ba-44b9-8766-9913f571ffd1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bc5f1a0adac8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "lWtEu0JVow4a",
    "outputId": "66497bc0-f08f-44a2-96e4-a7705300f728"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-eb4877392962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-1c0de7a06c6c>\u001b[0m in \u001b[0;36mprepare_datasets\u001b[0;34m(test_size, validation_size, data)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# add an axis to input sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mX_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WncuicyAY9_k",
    "outputId": "bd3c0742-78fe-40d4-9d67-378a44845cef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['chroma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "I1m8am6UOofi",
    "outputId": "85fb3f88-2664-4369-b1bd-814d25a569f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7288013 , 0.75724936, 0.83448064, 0.81660644, 0.76865371,\n",
       "        0.62699085, 0.5883597 , 0.56742175, 0.58321921, 0.59538077,\n",
       "        0.59700023, 0.60815506, 0.61369623, 0.54508944, 0.60310508,\n",
       "        0.56123704, 0.49720041, 0.55792345, 0.63186636, 0.55324167,\n",
       "        0.58548555, 0.65506838, 0.75310949, 0.8313863 , 0.82142502,\n",
       "        0.82192932, 0.57785087, 0.65255588, 0.51218425, 0.63614095,\n",
       "        0.47345992, 0.55523374, 0.44203873, 0.48525513, 0.40575816,\n",
       "        0.55065949, 0.43363816, 0.4333998 , 0.47565911, 0.36319805,\n",
       "        0.30794827, 0.40454989, 0.31559102, 0.30951695, 0.34457948,\n",
       "        0.32261498, 0.32748413],\n",
       "       [0.35089718, 0.41995519, 0.53942848, 0.51436999, 0.34981604,\n",
       "        0.16274504, 0.10951279, 0.09213558, 0.1154954 , 0.2092654 ,\n",
       "        0.24597213, 0.27875345, 0.24463225, 0.21947437, 0.237796  ,\n",
       "        0.2444938 , 0.24799479, 0.2758819 , 0.27929768, 0.24682381,\n",
       "        0.25737952, 0.31469437, 0.46132661, 0.62721023, 0.57127657,\n",
       "        0.60028499, 0.38773206, 0.46409459, 0.45834887, 0.44472653,\n",
       "        0.38296645, 0.38970407, 0.33511957, 0.30245803, 0.30268073,\n",
       "        0.38534949, 0.3663854 , 0.37448265, 0.36824746, 0.32970978,\n",
       "        0.36971406, 0.39240316, 0.37469311, 0.36754971, 0.35848597,\n",
       "        0.36969227, 0.42910495],\n",
       "       [0.4179455 , 0.39383415, 0.47139716, 0.32806465, 0.23946483,\n",
       "        0.14847505, 0.13415149, 0.12337456, 0.14630837, 0.21129075,\n",
       "        0.25248135, 0.23110915, 0.20949289, 0.20667048, 0.19306957,\n",
       "        0.22405842, 0.2525388 , 0.2535672 , 0.22634367, 0.23801658,\n",
       "        0.18652207, 0.16256252, 0.33298232, 0.42889286, 0.44801712,\n",
       "        0.47815152, 0.36498915, 0.34219903, 0.26601723, 0.2187617 ,\n",
       "        0.18120394, 0.13691908, 0.16163385, 0.21431345, 0.16897009,\n",
       "        0.20505038, 0.25608394, 0.27081722, 0.20387122, 0.16867172,\n",
       "        0.22991134, 0.21396019, 0.19154165, 0.21679319, 0.22374638,\n",
       "        0.25234359, 0.28583924],\n",
       "       [0.2824623 , 0.34319445, 0.33964929, 0.21742969, 0.20738921,\n",
       "        0.13899506, 0.12771343, 0.11309593, 0.10097028, 0.12184557,\n",
       "        0.16464198, 0.18180081, 0.1795867 , 0.16528316, 0.16269345,\n",
       "        0.1970414 , 0.22053581, 0.22310346, 0.19834606, 0.20721916,\n",
       "        0.21924381, 0.24559216, 0.319891  , 0.511576  , 0.41694985,\n",
       "        0.43296669, 0.28999183, 0.30168873, 0.24287783, 0.13311331,\n",
       "        0.2639167 , 0.16728014, 0.18492127, 0.15094525, 0.17669987,\n",
       "        0.16199226, 0.19084829, 0.25850869, 0.23471274, 0.15677112,\n",
       "        0.22763005, 0.1914798 , 0.22861678, 0.19508959, 0.26300583,\n",
       "        0.29284457, 0.25015941],\n",
       "       [0.48349031, 0.48574294, 0.42958099, 0.28390857, 0.26456212,\n",
       "        0.17823877, 0.15448753, 0.1490716 , 0.11822319, 0.11941317,\n",
       "        0.12682267, 0.16263004, 0.17954708, 0.16951985, 0.1711148 ,\n",
       "        0.20857541, 0.23818851, 0.23661619, 0.23413901, 0.21266734,\n",
       "        0.2054391 , 0.24859116, 0.31062943, 0.62928616, 0.68393556,\n",
       "        0.54481138, 0.42445359, 0.52359945, 0.41210114, 0.3342629 ,\n",
       "        0.38285954, 0.28978438, 0.25055451, 0.21959409, 0.24149607,\n",
       "        0.26712322, 0.22082974, 0.33445593, 0.33455042, 0.30867299,\n",
       "        0.32638637, 0.31711703, 0.29181681, 0.26072219, 0.33595646,\n",
       "        0.35753868, 0.3580564 ],\n",
       "       [0.5003511 , 0.54167652, 0.70123515, 0.52407842, 0.52593234,\n",
       "        0.42485952, 0.42425976, 0.38148125, 0.41378351, 0.42530148,\n",
       "        0.37843882, 0.39835999, 0.38097795, 0.36733132, 0.33228706,\n",
       "        0.38360744, 0.38714186, 0.42260338, 0.41524841, 0.43876129,\n",
       "        0.45930902, 0.48864263, 0.65023489, 0.82913463, 0.94572776,\n",
       "        0.72706071, 0.72381623, 0.6685874 , 0.76892536, 0.7199253 ,\n",
       "        0.71089036, 0.73057564, 0.69911114, 0.71429471, 0.69521414,\n",
       "        0.75292579, 0.73033868, 0.73807279, 0.67721489, 0.70730313,\n",
       "        0.69884568, 0.6858221 , 0.65422852, 0.62147903, 0.5998471 ,\n",
       "        0.57332614, 0.57011075],\n",
       "       [0.52875192, 0.55690579, 0.90710866, 0.82224617, 0.67968687,\n",
       "        0.52749438, 0.52310073, 0.54043979, 0.58245489, 0.59988289,\n",
       "        0.57235422, 0.55106401, 0.49378358, 0.41512974, 0.36162653,\n",
       "        0.37861072, 0.38400834, 0.37204387, 0.3718287 , 0.38541555,\n",
       "        0.41269254, 0.51317545, 0.77219921, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        ],\n",
       "       [0.54086479, 0.54709171, 0.67261773, 0.51983659, 0.41925694,\n",
       "        0.28313869, 0.28485682, 0.29415962, 0.34607057, 0.3696991 ,\n",
       "        0.42034726, 0.34984733, 0.29798679, 0.21262609, 0.17549661,\n",
       "        0.20030605, 0.23506596, 0.24783092, 0.2470048 , 0.23010206,\n",
       "        0.21219325, 0.30418154, 0.56723186, 0.85725155, 0.7182361 ,\n",
       "        0.75281659, 0.62979783, 0.60273829, 0.4859248 , 0.5239141 ,\n",
       "        0.48414424, 0.45048686, 0.45950338, 0.48979748, 0.48017986,\n",
       "        0.46453216, 0.48457755, 0.48423376, 0.48760651, 0.48523204,\n",
       "        0.47688933, 0.51544847, 0.55486019, 0.5718366 , 0.55871313,\n",
       "        0.56043876, 0.56665243],\n",
       "       [0.24801165, 0.29509667, 0.25782927, 0.19114538, 0.14239238,\n",
       "        0.10931741, 0.11236059, 0.12193976, 0.16664673, 0.2696013 ,\n",
       "        0.33485115, 0.29013234, 0.2307269 , 0.1830748 , 0.18226918,\n",
       "        0.17586092, 0.17310794, 0.16953934, 0.17873991, 0.21470178,\n",
       "        0.24610699, 0.30369931, 0.4810098 , 0.67507858, 0.59042689,\n",
       "        0.49183486, 0.30394008, 0.30434559, 0.19959692, 0.17396163,\n",
       "        0.16534315, 0.15983784, 0.11496885, 0.12685908, 0.13444037,\n",
       "        0.14944504, 0.11207552, 0.12782866, 0.09682908, 0.10045158,\n",
       "        0.07752087, 0.09344522, 0.14529075, 0.19311243, 0.19862633,\n",
       "        0.23646108, 0.29009739],\n",
       "       [0.34782881, 0.4108713 , 0.38927128, 0.28899494, 0.22403284,\n",
       "        0.13923839, 0.11067011, 0.1023532 , 0.12840503, 0.2409123 ,\n",
       "        0.31583105, 0.27580808, 0.2186752 , 0.19196566, 0.21111029,\n",
       "        0.20513247, 0.17835509, 0.13642065, 0.10452756, 0.09774461,\n",
       "        0.12638149, 0.18978664, 0.36234379, 0.60412233, 0.48325949,\n",
       "        0.4481277 , 0.30153461, 0.40560856, 0.32701131, 0.2878296 ,\n",
       "        0.25949501, 0.22367257, 0.20432968, 0.1605366 , 0.14500364,\n",
       "        0.16262834, 0.14779502, 0.20511221, 0.12781082, 0.12637128,\n",
       "        0.12644628, 0.15861185, 0.16055334, 0.1543925 , 0.16619139,\n",
       "        0.21194533, 0.25104357],\n",
       "       [1.        , 1.        , 1.        , 0.88057908, 0.84370162,\n",
       "        0.74250531, 0.72005093, 0.72495783, 0.71416291, 0.70518731,\n",
       "        0.75128959, 0.80641822, 0.77307641, 0.72093315, 0.71612501,\n",
       "        0.69691182, 0.68370538, 0.68129144, 0.69680803, 0.71677796,\n",
       "        0.7454012 , 0.75613949, 0.86876353, 0.95722206, 0.66165647,\n",
       "        0.64264943, 0.49058454, 0.4554615 , 0.36614095, 0.37557121,\n",
       "        0.32541571, 0.28618656, 0.3379193 , 0.24462612, 0.23239127,\n",
       "        0.20808796, 0.25618701, 0.24686633, 0.18510879, 0.20127152,\n",
       "        0.18744706, 0.16559011, 0.16953256, 0.14639916, 0.16394158,\n",
       "        0.18307587, 0.16197271],\n",
       "       [0.62435419, 0.70008244, 0.94437151, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.93521399, 0.78915807,\n",
       "        0.78893796, 0.56047497, 0.58366387, 0.5081874 , 0.5254716 ,\n",
       "        0.4033312 , 0.42281251, 0.42641167, 0.42118868, 0.34908952,\n",
       "        0.4213055 , 0.4026606 , 0.32756171, 0.3427556 , 0.28469196,\n",
       "        0.24456208, 0.26995397, 0.22564857, 0.21406123, 0.24103505,\n",
       "        0.22290446, 0.18767935]])"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data[\"chroma\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZIOCss_xYMPg",
    "outputId": "73aca293-eea1-4667-c962-377030467d21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7288013022389698,\n",
       "  0.7572493567955018,\n",
       "  0.834480636331949,\n",
       "  0.8166064447882895,\n",
       "  0.7686537063127805,\n",
       "  0.6269908500166702,\n",
       "  0.5883597001008098,\n",
       "  0.5674217538980294,\n",
       "  0.5832192064957951,\n",
       "  0.5953807736285751,\n",
       "  0.597000234069787,\n",
       "  0.6081550612255971,\n",
       "  0.6136962331968159,\n",
       "  0.5450894366834673,\n",
       "  0.6031050797302732,\n",
       "  0.5612370426491379,\n",
       "  0.49720040695923945,\n",
       "  0.5579234510777252,\n",
       "  0.6318663578176883,\n",
       "  0.5532416735825664,\n",
       "  0.5854855492988712,\n",
       "  0.6550683827275349,\n",
       "  0.7531094877424219,\n",
       "  0.8313862994021818,\n",
       "  0.8214250179752771,\n",
       "  0.8219293152885315,\n",
       "  0.5778508724149634,\n",
       "  0.6525558827902895,\n",
       "  0.5121842548483573,\n",
       "  0.6361409534561175,\n",
       "  0.4734599241973687,\n",
       "  0.5552337411153029,\n",
       "  0.4420387335310675,\n",
       "  0.4852551315761424,\n",
       "  0.4057581582932399,\n",
       "  0.5506594900528115,\n",
       "  0.43363815756208596,\n",
       "  0.4333998031069389,\n",
       "  0.475659114704717,\n",
       "  0.36319805198229344,\n",
       "  0.30794826504551037,\n",
       "  0.4045498855986784,\n",
       "  0.31559101952157786,\n",
       "  0.30951695009468316,\n",
       "  0.3445794800208758,\n",
       "  0.3226149843061307,\n",
       "  0.32748413176774],\n",
       " [0.3508971836990446,\n",
       "  0.41995519329583864,\n",
       "  0.539428479343749,\n",
       "  0.5143699942623042,\n",
       "  0.3498160395335127,\n",
       "  0.16274503617513467,\n",
       "  0.10951279376457541,\n",
       "  0.09213557986369537,\n",
       "  0.11549539794119647,\n",
       "  0.20926540450279582,\n",
       "  0.24597212551973965,\n",
       "  0.2787534503982154,\n",
       "  0.2446322528292197,\n",
       "  0.21947437415969168,\n",
       "  0.23779600272493895,\n",
       "  0.24449379687259995,\n",
       "  0.24799479397104546,\n",
       "  0.27588190294297865,\n",
       "  0.27929768312222664,\n",
       "  0.24682381095718006,\n",
       "  0.257379517375434,\n",
       "  0.314694367099651,\n",
       "  0.4613266065475961,\n",
       "  0.6272102266886554,\n",
       "  0.571276571337253,\n",
       "  0.6002849910680536,\n",
       "  0.3877320581686313,\n",
       "  0.4640945865333485,\n",
       "  0.4583488675373728,\n",
       "  0.44472652636029625,\n",
       "  0.3829664539352592,\n",
       "  0.389704068272416,\n",
       "  0.33511957143905574,\n",
       "  0.30245803371813684,\n",
       "  0.30268072841950233,\n",
       "  0.38534948507830097,\n",
       "  0.36638539542604026,\n",
       "  0.37448264807961884,\n",
       "  0.36824746059904995,\n",
       "  0.3297097822781324,\n",
       "  0.36971406057558814,\n",
       "  0.392403164042968,\n",
       "  0.37469310978125303,\n",
       "  0.36754971274049125,\n",
       "  0.3584859702117919,\n",
       "  0.36969227317578035,\n",
       "  0.4291049463973307],\n",
       " [0.4179455035851387,\n",
       "  0.39383415067156585,\n",
       "  0.47139716014760513,\n",
       "  0.3280646461123178,\n",
       "  0.2394648292870587,\n",
       "  0.14847504992252744,\n",
       "  0.13415149249371677,\n",
       "  0.12337455805806546,\n",
       "  0.1463083653320749,\n",
       "  0.21129075225867386,\n",
       "  0.25248135027314117,\n",
       "  0.23110914930989593,\n",
       "  0.20949288655567694,\n",
       "  0.20667048097186236,\n",
       "  0.19306956666018013,\n",
       "  0.22405841875099927,\n",
       "  0.25253879829782855,\n",
       "  0.25356720320820747,\n",
       "  0.2263436717866702,\n",
       "  0.23801658422050131,\n",
       "  0.1865220663643431,\n",
       "  0.1625625164519254,\n",
       "  0.33298231626952973,\n",
       "  0.4288928590168919,\n",
       "  0.4480171185857429,\n",
       "  0.47815152401554334,\n",
       "  0.3649891479733633,\n",
       "  0.3421990339311608,\n",
       "  0.266017231058131,\n",
       "  0.21876169644278318,\n",
       "  0.18120393823617478,\n",
       "  0.13691908104090153,\n",
       "  0.16163385271112352,\n",
       "  0.2143134505173196,\n",
       "  0.16897008603766073,\n",
       "  0.20505037529104508,\n",
       "  0.25608394442933036,\n",
       "  0.27081721728627356,\n",
       "  0.2038712214573236,\n",
       "  0.16867172166240296,\n",
       "  0.2299113416141647,\n",
       "  0.21396018704422953,\n",
       "  0.19154164586705097,\n",
       "  0.21679319029905117,\n",
       "  0.2237463785911682,\n",
       "  0.25234358606994034,\n",
       "  0.2858392432576361],\n",
       " [0.2824622955576027,\n",
       "  0.3431944461118807,\n",
       "  0.3396492936206729,\n",
       "  0.2174296872625944,\n",
       "  0.2073892084002282,\n",
       "  0.13899506130386902,\n",
       "  0.12771343343184557,\n",
       "  0.11309592694758736,\n",
       "  0.1009702785937157,\n",
       "  0.12184556639586992,\n",
       "  0.16464197983568735,\n",
       "  0.18180080825464806,\n",
       "  0.17958670378384461,\n",
       "  0.1652831640766618,\n",
       "  0.16269345410374472,\n",
       "  0.19704140414058946,\n",
       "  0.22053580897714137,\n",
       "  0.22310345654567484,\n",
       "  0.19834606327351625,\n",
       "  0.2072191627242948,\n",
       "  0.21924380748515077,\n",
       "  0.24559215791101402,\n",
       "  0.31989100266496895,\n",
       "  0.5115760049451229,\n",
       "  0.41694985242720617,\n",
       "  0.43296669128878273,\n",
       "  0.28999182758734277,\n",
       "  0.30168872988516215,\n",
       "  0.24287783351863185,\n",
       "  0.1331133121719306,\n",
       "  0.26391670417376256,\n",
       "  0.1672801420039659,\n",
       "  0.18492127491143376,\n",
       "  0.15094525224725502,\n",
       "  0.17669987360176032,\n",
       "  0.16199226129235192,\n",
       "  0.19084828537942203,\n",
       "  0.2585086939390477,\n",
       "  0.23471273968186973,\n",
       "  0.15677112097417334,\n",
       "  0.2276300488344609,\n",
       "  0.19147979645070265,\n",
       "  0.22861677882725925,\n",
       "  0.19508959307350793,\n",
       "  0.26300583122881266,\n",
       "  0.2928445686939433,\n",
       "  0.2501594133699911],\n",
       " [0.48349030975783414,\n",
       "  0.48574293859542406,\n",
       "  0.42958098651366555,\n",
       "  0.2839085700486974,\n",
       "  0.2645621166780167,\n",
       "  0.178238769295026,\n",
       "  0.15448753483043176,\n",
       "  0.14907160076050974,\n",
       "  0.11822318700671286,\n",
       "  0.11941316985803102,\n",
       "  0.126822665464448,\n",
       "  0.16263004342223908,\n",
       "  0.17954708151240456,\n",
       "  0.16951985102617534,\n",
       "  0.17111480493548392,\n",
       "  0.2085754076561111,\n",
       "  0.23818851190274823,\n",
       "  0.23661619191992933,\n",
       "  0.23413900932832069,\n",
       "  0.21266733719394723,\n",
       "  0.20543909510345462,\n",
       "  0.24859115861364944,\n",
       "  0.31062942539955124,\n",
       "  0.6292861600515877,\n",
       "  0.6839355603903775,\n",
       "  0.5448113847360524,\n",
       "  0.4244535869246588,\n",
       "  0.5235994490567817,\n",
       "  0.4121011371910252,\n",
       "  0.33426289521185265,\n",
       "  0.3828595442600189,\n",
       "  0.28978438487523495,\n",
       "  0.25055451468449247,\n",
       "  0.2195940911666976,\n",
       "  0.24149607491178668,\n",
       "  0.2671232182382112,\n",
       "  0.22082974471641684,\n",
       "  0.33445592855991313,\n",
       "  0.33455042304465116,\n",
       "  0.3086729884157282,\n",
       "  0.3263863662985642,\n",
       "  0.3171170303289893,\n",
       "  0.2918168077344705,\n",
       "  0.26072219332110336,\n",
       "  0.3359564634246611,\n",
       "  0.3575386764620323,\n",
       "  0.3580564034815428],\n",
       " [0.5003510952909248,\n",
       "  0.5416765160980097,\n",
       "  0.7012351509850385,\n",
       "  0.5240784173461902,\n",
       "  0.5259323402609402,\n",
       "  0.4248595202517013,\n",
       "  0.42425975731108984,\n",
       "  0.38148124839232816,\n",
       "  0.4137835132446194,\n",
       "  0.42530147529458284,\n",
       "  0.37843881997262596,\n",
       "  0.39835999036166075,\n",
       "  0.38097795186984035,\n",
       "  0.36733132361097653,\n",
       "  0.332287055411613,\n",
       "  0.3836074359669473,\n",
       "  0.3871418563926695,\n",
       "  0.4226033813294448,\n",
       "  0.41524840687948517,\n",
       "  0.4387612907067599,\n",
       "  0.4593090207417681,\n",
       "  0.48864263166634114,\n",
       "  0.6502348940980804,\n",
       "  0.8291346347176322,\n",
       "  0.9457277639070791,\n",
       "  0.7270607076187936,\n",
       "  0.7238162319365551,\n",
       "  0.668587395331858,\n",
       "  0.7689253600427406,\n",
       "  0.7199253018317479,\n",
       "  0.7108903600126759,\n",
       "  0.7305756351397792,\n",
       "  0.699111136807779,\n",
       "  0.7142947073766208,\n",
       "  0.6952141388016108,\n",
       "  0.7529257893730569,\n",
       "  0.7303386830647454,\n",
       "  0.7380727930343962,\n",
       "  0.6772148941497685,\n",
       "  0.7073031328867071,\n",
       "  0.6988456769365236,\n",
       "  0.6858220951120956,\n",
       "  0.6542285165697732,\n",
       "  0.6214790319825771,\n",
       "  0.599847097042987,\n",
       "  0.5733261359756027,\n",
       "  0.570110746960492],\n",
       " [0.5287519209548125,\n",
       "  0.5569057881335564,\n",
       "  0.9071086580038511,\n",
       "  0.8222461720045914,\n",
       "  0.679686869427175,\n",
       "  0.5274943777215255,\n",
       "  0.5231007341490543,\n",
       "  0.5404397922004184,\n",
       "  0.5824548943113963,\n",
       "  0.5998828903871598,\n",
       "  0.5723542160095618,\n",
       "  0.5510640073826318,\n",
       "  0.49378358460503635,\n",
       "  0.4151297361740067,\n",
       "  0.3616265258019935,\n",
       "  0.37861071505089183,\n",
       "  0.3840083424269551,\n",
       "  0.3720438679566727,\n",
       "  0.37182869965088966,\n",
       "  0.3854155473446012,\n",
       "  0.41269253692666236,\n",
       "  0.5131754515103377,\n",
       "  0.7721992086136917,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [0.5408647914389612,\n",
       "  0.5470917104040921,\n",
       "  0.6726177251834294,\n",
       "  0.5198365947559965,\n",
       "  0.4192569368459371,\n",
       "  0.28313868720108537,\n",
       "  0.2848568186794645,\n",
       "  0.29415962105808363,\n",
       "  0.3460705690692413,\n",
       "  0.3696990968141634,\n",
       "  0.42034726165203307,\n",
       "  0.3498473309219183,\n",
       "  0.29798679456765964,\n",
       "  0.21262608935407706,\n",
       "  0.1754966093925842,\n",
       "  0.20030604908633778,\n",
       "  0.23506595838138594,\n",
       "  0.2478309160543574,\n",
       "  0.2470047952255249,\n",
       "  0.23010205737381462,\n",
       "  0.21219324525320304,\n",
       "  0.30418154449591916,\n",
       "  0.5672318555219718,\n",
       "  0.8572515523317655,\n",
       "  0.7182360989775995,\n",
       "  0.7528165949515668,\n",
       "  0.6297978271005894,\n",
       "  0.6027382884286485,\n",
       "  0.4859247954064446,\n",
       "  0.5239141018925069,\n",
       "  0.484144235772629,\n",
       "  0.4504868606997251,\n",
       "  0.45950338044480193,\n",
       "  0.48979748427205844,\n",
       "  0.480179858399622,\n",
       "  0.4645321648917212,\n",
       "  0.48457755316432044,\n",
       "  0.4842337640743045,\n",
       "  0.48760650599969213,\n",
       "  0.48523203510137597,\n",
       "  0.4768893310656921,\n",
       "  0.5154484668177451,\n",
       "  0.5548601867567238,\n",
       "  0.5718365996443225,\n",
       "  0.5587131303268001,\n",
       "  0.5604387611997832,\n",
       "  0.5666524296572911],\n",
       " [0.24801164723128385,\n",
       "  0.2950966737408821,\n",
       "  0.2578292702018689,\n",
       "  0.19114538048829524,\n",
       "  0.14239237511974162,\n",
       "  0.10931741359022965,\n",
       "  0.11236059328874941,\n",
       "  0.12193976271433836,\n",
       "  0.16664672758422416,\n",
       "  0.2696012994332439,\n",
       "  0.3348511463506617,\n",
       "  0.2901323430457121,\n",
       "  0.23072689783800146,\n",
       "  0.18307480247021682,\n",
       "  0.182269177909911,\n",
       "  0.17586091909185814,\n",
       "  0.17310794285199668,\n",
       "  0.16953933970851529,\n",
       "  0.17873991164341538,\n",
       "  0.2147017833029156,\n",
       "  0.24610699304001557,\n",
       "  0.3036993094922792,\n",
       "  0.48100979790441123,\n",
       "  0.6750785842692777,\n",
       "  0.5904268896103917,\n",
       "  0.49183485970935803,\n",
       "  0.3039400780935568,\n",
       "  0.30434558935857753,\n",
       "  0.19959692133633625,\n",
       "  0.17396163027815645,\n",
       "  0.165343148261463,\n",
       "  0.15983784452133995,\n",
       "  0.11496885283612115,\n",
       "  0.12685908093362247,\n",
       "  0.13444037107028003,\n",
       "  0.1494450378259266,\n",
       "  0.11207551931803665,\n",
       "  0.12782865563153897,\n",
       "  0.09682907906284513,\n",
       "  0.10045158029715609,\n",
       "  0.07752086533429449,\n",
       "  0.09344522474140893,\n",
       "  0.14529075257131344,\n",
       "  0.1931124347218033,\n",
       "  0.19862633019082684,\n",
       "  0.23646107598591803,\n",
       "  0.2900973934414595],\n",
       " [0.34782881294211465,\n",
       "  0.41087129736581507,\n",
       "  0.38927128277352036,\n",
       "  0.2889949389893348,\n",
       "  0.22403284088880956,\n",
       "  0.13923838822853463,\n",
       "  0.11067011027993406,\n",
       "  0.10235319564218912,\n",
       "  0.1284050283317123,\n",
       "  0.24091230204621303,\n",
       "  0.3158310488192057,\n",
       "  0.27580808316862965,\n",
       "  0.21867519815991218,\n",
       "  0.19196566471643509,\n",
       "  0.21111029415091687,\n",
       "  0.20513246943967872,\n",
       "  0.17835509200384883,\n",
       "  0.13642064520457728,\n",
       "  0.10452755682941452,\n",
       "  0.09774461321328265,\n",
       "  0.1263814916794046,\n",
       "  0.189786637047126,\n",
       "  0.36234378794265637,\n",
       "  0.6041223314264457,\n",
       "  0.4832594854100476,\n",
       "  0.4481277032369326,\n",
       "  0.3015346141734846,\n",
       "  0.405608559379221,\n",
       "  0.3270113144451359,\n",
       "  0.2878295984372902,\n",
       "  0.2594950085243962,\n",
       "  0.2236725693213765,\n",
       "  0.20432968475275148,\n",
       "  0.1605366014694464,\n",
       "  0.14500363649592288,\n",
       "  0.1626283445327523,\n",
       "  0.14779501968868197,\n",
       "  0.20511220920132683,\n",
       "  0.12781082471266822,\n",
       "  0.1263712816274859,\n",
       "  0.12644627776922104,\n",
       "  0.15861185334794362,\n",
       "  0.1605533401336287,\n",
       "  0.1543925026865733,\n",
       "  0.16619139199019567,\n",
       "  0.21194533154101858,\n",
       "  0.2510435654031854],\n",
       " [1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.8805790807856785,\n",
       "  0.843701616934572,\n",
       "  0.742505309304293,\n",
       "  0.7200509336829916,\n",
       "  0.7249578347841533,\n",
       "  0.7141629056043904,\n",
       "  0.7051873101038876,\n",
       "  0.751289590797755,\n",
       "  0.8064182166217002,\n",
       "  0.7730764132612016,\n",
       "  0.7209331459105356,\n",
       "  0.7161250123781309,\n",
       "  0.6969118152212957,\n",
       "  0.683705375420779,\n",
       "  0.6812914379854469,\n",
       "  0.6968080308606082,\n",
       "  0.7167779593347463,\n",
       "  0.7454011985004982,\n",
       "  0.7561394894144371,\n",
       "  0.8687635334857441,\n",
       "  0.9572220614163597,\n",
       "  0.6616564679569951,\n",
       "  0.6426494262955607,\n",
       "  0.49058453651568745,\n",
       "  0.4554615020342545,\n",
       "  0.36614094696630617,\n",
       "  0.3755712053146157,\n",
       "  0.32541571047206536,\n",
       "  0.28618656303013984,\n",
       "  0.3379192982529817,\n",
       "  0.24462611514005608,\n",
       "  0.2323912665660167,\n",
       "  0.20808796155254952,\n",
       "  0.25618700834595914,\n",
       "  0.24686633369222974,\n",
       "  0.18510878917988463,\n",
       "  0.20127151583225011,\n",
       "  0.18744705950233564,\n",
       "  0.16559011342291383,\n",
       "  0.16953256104093786,\n",
       "  0.1463991649665449,\n",
       "  0.16394157950423469,\n",
       "  0.183075865685662,\n",
       "  0.16197270684654652],\n",
       " [0.6243541931553298,\n",
       "  0.7000824378054977,\n",
       "  0.9443715103966818,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9352139888335637,\n",
       "  0.7891580668517959,\n",
       "  0.7889379553851978,\n",
       "  0.560474970279152,\n",
       "  0.5836638678671726,\n",
       "  0.5081874010600165,\n",
       "  0.5254716013910168,\n",
       "  0.40333120039623066,\n",
       "  0.42281250890205446,\n",
       "  0.426411669743442,\n",
       "  0.4211886760607065,\n",
       "  0.34908951929112364,\n",
       "  0.42130549702366665,\n",
       "  0.4026606048862286,\n",
       "  0.3275617132200743,\n",
       "  0.3427555976885451,\n",
       "  0.28469195586617796,\n",
       "  0.24456208165918417,\n",
       "  0.2699539656069785,\n",
       "  0.22564857291125578,\n",
       "  0.2140612294129109,\n",
       "  0.24103504787901778,\n",
       "  0.22290445886259788,\n",
       "  0.18767934715096204]]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"chroma\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "dRNCbmb615uX",
    "outputId": "da030ba4-9b57-4a7d-c520-80b1e3907165"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list([1.0, 1.0, 0.921459132091177, 0.8425096004325365, 0.7818169595536819, 0.7557599637918447, 0.787966509468703, 0.8433780645275688, 0.9585288606699726, 0.9195850638424878, 0.7148726266539676, 0.4889599594745931, 0.3691376531544215, 0.2772072399916381, 0.2532487847401799, 0.26018992194895635, 0.21863379558174703, 0.17250024972372768, 0.14091192561580715, 0.13975586792258657, 0.12831543639491927, 0.12908232476477982, 0.11593384140353465, 0.11417479471416508, 0.11349497794515002, 0.119837864267342, 0.12409849080151195, 0.12233008270820675, 0.1220512860966902, 0.11208661079799202, 0.14714336075493023, 0.22214714358976428, 0.2897846101369739, 0.3212523841715654, 0.37551383407667155, 0.39007963418547276, 0.35778753020434995, 0.3081538897242404, 0.24908210761817048, 0.22701136888951903, 0.22423208266462558, 0.24011447346695886, 0.248208671780013, 0.26470507181851405, 0.2291580034188743])],\n",
       "       [list([0.3998285841353844, 0.3855430102240854, 0.3278434701431348, 0.2758905435862441, 0.24134160811211527, 0.25858376061730565, 0.3051555914059491, 0.45280575133291123, 0.6732936158331065, 0.5957262393789715, 0.4970247444767685, 0.3558906618788983, 0.2609286900853436, 0.19403411020577288, 0.15525464699004096, 0.1153383963783854, 0.14561397697921893, 0.09668117456022383, 0.06837301468127929, 0.06056726111203963, 0.05056300619409561, 0.04869438016581659, 0.04750940306923811, 0.05305091508246333, 0.05669873919873655, 0.06465113616747721, 0.07316525047455782, 0.08983225309734778, 0.11643581193626837, 0.13797966446483134, 0.169117056733692, 0.24784324842404862, 0.3399567349507717, 0.4587711228615331, 0.5607922984680386, 0.6008434681225338, 0.48416965483645114, 0.3596024701886663, 0.2950415673262583, 0.25075459662631355, 0.22590225356308447, 0.22275751389878157, 0.22453920228905397, 0.23513821054979897, 0.39161292577833473])],\n",
       "       [list([0.20506110149696816, 0.18646372385695073, 0.16354004317195936, 0.16245856362388336, 0.17401106454587878, 0.1922998799052581, 0.1984538957589581, 0.3512887609668002, 0.5818337195219669, 0.5302882385551471, 0.4734078407613956, 0.3901481635830311, 0.287683359288675, 0.23263631913735225, 0.18097876531473578, 0.16056712382904903, 0.15060348735528564, 0.1255314523190295, 0.10153937223249578, 0.10067156923896944, 0.09875886932453035, 0.0939687881140797, 0.09771069629117382, 0.09121965220082441, 0.08602187794015971, 0.097655520006573, 0.1078346195653531, 0.1407934849652244, 0.17735407185623198, 0.242582575614862, 0.28032474810065117, 0.28528052334721066, 0.30621783503187827, 0.33128366356882855, 0.46425089701446354, 0.6434933303054051, 0.6786134922735683, 0.6601374307178367, 0.6518342266385689, 0.6668303762817265, 0.6996450460708377, 0.7344759836925284, 0.7640712172642603, 0.7603352835961273, 0.8675476379508489])],\n",
       "       [list([0.1646955699275191, 0.16378227671722015, 0.1463577508394985, 0.13713471279980102, 0.13003145124092688, 0.15336774855312424, 0.20932918513552137, 0.3410945247948976, 0.659756220968068, 0.8128444257558768, 0.8159004753162908, 0.7964699020456112, 0.7714290624787534, 0.752347740774778, 0.7370644286754934, 0.7100033176649095, 0.7341617732275376, 0.7102052299705289, 0.7107729619120076, 0.7141596497176368, 0.7134221925454902, 0.7081472552913509, 0.7146762631402552, 0.7166866735639437, 0.7137541727930737, 0.7184743751453789, 0.7270741729653072, 0.755292904586625, 0.8025832738738773, 0.8513801899705455, 0.8877204976933504, 0.9408302156282076, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])],\n",
       "       [list([0.1632419740927472, 0.14845692817431352, 0.1473982326581088, 0.13991238560141536, 0.13359731841715877, 0.15278654109215584, 0.1937988752805002, 0.3021571323461868, 0.6078640942100512, 0.9635853998453863, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9936782476357268, 0.9025736759406245, 0.8117009453507504, 0.7228546368200364, 0.6550253418938068, 0.6040532544010515, 0.5626236217671712, 0.5113383945971633, 0.4773966189524745, 0.4556411541085288, 0.4106860480579869, 0.39715033482877615, 0.3841874751473755])],\n",
       "       [list([0.2179861308867318, 0.2002633483454485, 0.1799227069337293, 0.16284377434727657, 0.15635952355725755, 0.1603418602587431, 0.18675111744548198, 0.2884787955853567, 0.4344925723115158, 0.6285056658609545, 0.4672244171146417, 0.5564536969250925, 0.4427335701495422, 0.5177941524103528, 0.5151926780707129, 0.43972051229599407, 0.45887802059230204, 0.4298628776445294, 0.43301327758067365, 0.43234578167595206, 0.427568956686378, 0.43065898648055695, 0.4245060766583048, 0.42398389247360097, 0.42315180054118273, 0.4194292422644704, 0.4359731877441843, 0.4442126608146606, 0.47551891316421124, 0.49079665718025656, 0.4746883607612581, 0.44015825514749934, 0.38945509876173884, 0.3227697776624162, 0.2845593432907538, 0.31294424965206497, 0.2651386719505306, 0.22009119400664942, 0.17402293000909758, 0.12154703870494085, 0.12247986760910048, 0.11786286536573325, 0.13529132502681096, 0.17598117787727618, 0.22600123169437084])],\n",
       "       [list([0.4197823307895281, 0.40023372608707214, 0.37038687049574515, 0.3403639264730684, 0.3084961435405102, 0.2792853611503466, 0.2749891535742944, 0.29598983979742416, 0.3358556699275546, 0.3970849611520935, 0.34788038718765774, 0.30867360956157686, 0.2602507097656068, 0.23791362853315734, 0.1618666065481729, 0.1133591550172022, 0.07961393656823104, 0.04597652666863456, 0.03815053447407627, 0.03284921071600731, 0.030808813950983106, 0.026205248898955206, 0.04419203161897653, 0.04342655012822305, 0.04972008503469622, 0.04924484894202458, 0.06326274044139464, 0.07896873826775275, 0.11994408851644169, 0.15579774212674657, 0.16142227097520623, 0.1676392255916175, 0.18673195848469934, 0.2245053259552945, 0.24717783332772958, 0.23271791779399642, 0.24500167652452623, 0.20568571558615856, 0.17358680623216874, 0.14092398656043192, 0.11159290519592817, 0.11937044916102946, 0.12317270392201066, 0.16715342523484478, 0.1894955642351544])],\n",
       "       [list([0.4230846041341755, 0.3928130853105823, 0.3280930767747131, 0.2616191934780703, 0.21546457739270392, 0.19913158212572657, 0.19490927979902, 0.22649540914373464, 0.3409238001178727, 0.40128327615514786, 0.35094268026863934, 0.30029962217265255, 0.26707994312092287, 0.2005941315999943, 0.18825203589276993, 0.15604279137937122, 0.1401626172782017, 0.10358454665135598, 0.07350673331417255, 0.058465613944364864, 0.048042684277404976, 0.05902758943510277, 0.07420998289814514, 0.09005007857800841, 0.08585896305577943, 0.08405276469153908, 0.07276699355713728, 0.06638282895639841, 0.0889376951143041, 0.10087301771256647, 0.12900853141849852, 0.15480814549781313, 0.1780020427778279, 0.1837574971063026, 0.16870982715696342, 0.19007807095827628, 0.20543839485707305, 0.16339457305869454, 0.13160978379964997, 0.11445870182068674, 0.09985031918739909, 0.08404703966700443, 0.08464602957338997, 0.10558076673754846, 0.09124171942677553])],\n",
       "       [list([0.3878243333384175, 0.3773825286321318, 0.3103020495038243, 0.25270477742830694, 0.2076646982520194, 0.19237348080835734, 0.23050002497782568, 0.29847242252645456, 0.4247805523714961, 0.6044390928094227, 0.4823585752394717, 0.3820574791458219, 0.2991941375447953, 0.20308763550980188, 0.19150486715438284, 0.21432129694181365, 0.193943053699837, 0.17760227654449393, 0.12328952222274692, 0.1042379818032551, 0.10170866430301931, 0.10202477460217707, 0.11413025376084217, 0.13575559197009657, 0.13369425283266162, 0.11959231535273208, 0.0954202440318464, 0.08918275722532187, 0.09864621790833815, 0.12256157197954846, 0.1387947543364238, 0.1531075705158209, 0.19407754534017316, 0.20290405561966257, 0.1922653705593669, 0.18673235599454904, 0.12380328640193254, 0.07152419248610807, 0.06432967109535244, 0.06551946415732311, 0.0621783477136626, 0.060940604884022045, 0.06468307096899951, 0.07154843988169034, 0.12203648235635514])],\n",
       "       [list([0.6267585199500039, 0.588470755801285, 0.4829548655397107, 0.3737347494559372, 0.3024289428338475, 0.33000456876141343, 0.3695886111706379, 0.4602443698670292, 0.5969841219848875, 0.6409558241255952, 0.48745099771632183, 0.37212077667603344, 0.25686668799369583, 0.165425638305527, 0.1480682797962191, 0.15185503911348947, 0.16522139795015156, 0.14016344451436255, 0.09590099072547906, 0.08218084486625034, 0.07059582474713735, 0.07174999036430521, 0.059550470973128905, 0.08324929768288493, 0.08304125977777378, 0.07742261150816378, 0.07088034924895466, 0.06680924122114572, 0.08219473016015726, 0.100239782584734, 0.11746062107279015, 0.12192206990380207, 0.14534801665387975, 0.17335659108775212, 0.21404258710033902, 0.23964153329979515, 0.22225384306488166, 0.20142672820742344, 0.19534580770681856, 0.19616383553894257, 0.19311094543923782, 0.19416971018253937, 0.16734696287837514, 0.16772912994031206, 0.24289044041919])],\n",
       "       [list([0.6297971856663043, 0.7115365503953412, 0.7602285681525953, 0.744014150468439, 0.729598713371843, 0.730884125465931, 0.7668683727297201, 0.8187025177018219, 0.8212052234016705, 0.7302086974928318, 0.5163222377462522, 0.3352395399542624, 0.2943923268746902, 0.275959223965774, 0.2562923580789748, 0.27951331201542545, 0.2729858315206921, 0.2185784742696971, 0.19541082236032284, 0.1917425215045332, 0.19516710695335104, 0.189553029748399, 0.18238383784623913, 0.17562859286087085, 0.1818267590801729, 0.185491246739934, 0.18225488468683412, 0.1871229962289525, 0.189362758431924, 0.19310688688392982, 0.20436049793741232, 0.2349262572597083, 0.2822003688714509, 0.3286952948363603, 0.36184849294711185, 0.3577770011072234, 0.4016265862093172, 0.37570778791891246, 0.31622350679361333, 0.37498052975221613, 0.3254633689795437, 0.33013111366572573, 0.40954307056406614, 0.35135963422066613, 0.4747409070125796])],\n",
       "       [list([0.9031506956279214, 0.9720882303905558, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7203449227176045, 0.5006054875960131, 0.4328366863092015, 0.38326489360044796, 0.37988242625430696, 0.400994003026052, 0.3082426373380531, 0.26351693746791455, 0.27532599010422876, 0.2718783629677885, 0.2689198870550305, 0.26027849283134863, 0.24995763736056628, 0.24349786286466307, 0.24208167251168794, 0.2343510131490061, 0.2267624405619515, 0.21956635814707268, 0.21561453578971074, 0.2123292928063358, 0.23483700817268677, 0.268237160995911, 0.302822492302424, 0.3370259254574926, 0.3647640367021486, 0.3766518934723523, 0.40341121390953166, 0.37603296302821354, 0.294729310164988, 0.32830984578188277, 0.30124844068179135, 0.33248715099716175, 0.42391876185444205, 0.448774954157318, 0.40018957835008573])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 219,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NoDUdxoo15q4"
   },
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3vlY4xQI15nM",
    "outputId": "999c908b-82af-44af-c1bc-dfc993a211b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1, 1)"
      ]
     },
     "execution_count": 194,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "C3eLx8arEbiR",
    "outputId": "e064d5d6-da97-4ea0-a6db-301c6e857384"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list([0.6234039599703074, 0.37661644085578255, 0.3168832563395006, 0.2866493357834577, 0.27497397868156964, 0.31080917022958426, 0.37008477731291994, 0.45613058497212944, 0.5550712329491228, 0.27396993219754584, 0.2237661429465293, 0.22881507273820695, 0.3005191231947147, 0.33773862129780147, 0.4122238045008005, 0.45708267093886684, 0.5551373985651784, 0.5730173510311065, 0.5858487519357544, 0.6497741377870693, 0.6799904377205382, 0.5907583018354723, 0.6180051059508019, 0.5788365141365021, 0.5919438801139771, 0.5798578608850993, 0.540347656280515, 0.5501907579850024, 0.4828329647671563, 0.41423602889967326, 0.40401073101168683, 0.43242404547096547, 0.47394704150825, 0.6088859271643858, 0.7450792991283116, 0.9090209816552306, 0.31257257888469514, 0.35591137744396617, 0.4937941694281021, 0.5586421815389166, 0.5624105937669147, 0.5464021457266203, 0.5498884808381371, 0.563428348720709, 0.688885223746597])],\n",
       "       [list([0.13096763171262008, 0.09427673960543258, 0.08929368633250136, 0.10261662146940716, 0.11504855414870546, 0.15121510943840616, 0.15779063962955137, 0.21309667695966125, 0.3478776628859093, 0.26185194001362616, 0.14880000328055737, 0.09352931446632048, 0.12233966530478747, 0.12641061939757223, 0.11472435703300254, 0.07726891189667645, 0.10969813717099211, 0.15431518445526124, 0.19836586237152376, 0.2793234553165662, 0.27525548768215624, 0.21001034115217249, 0.3035586759900832, 0.14456327982578804, 0.1366317228233493, 0.1527805375866694, 0.1040580575922009, 0.16155330246949834, 0.14185433185132032, 0.14459871115778122, 0.15649711491441076, 0.2506788757486608, 0.3551646279463601, 0.4634500449728634, 0.5099841965417461, 0.6875672086863923, 0.2336015947988543, 0.08805261877877879, 0.0836363784924598, 0.07428991308134943, 0.09113639114653768, 0.07025847560709811, 0.06441117810324182, 0.05921280045399035, 0.73326306924716])],\n",
       "       [list([0.8322556572595871, 0.5626419548369421, 0.5926466771399731, 0.5796913928216971, 0.647234771940355, 0.6082296822644295, 0.5988600470763152, 0.6183490921236394, 0.4304831255666272, 0.2168595579982497, 0.09086060023264105, 0.08221941087676908, 0.10732615360512089, 0.11294720938291888, 0.1428047350250927, 0.11370693849688804, 0.11635992380518814, 0.12691870400770885, 0.14952066250499113, 0.18065437453850997, 0.16391149116017634, 0.15862063193813952, 0.20495063813132447, 0.12675206971551722, 0.09882565948983751, 0.12004506211692237, 0.16142154661156422, 0.22393745690054584, 0.2946182546062297, 0.3103235994384199, 0.38990499637144893, 0.437413630483615, 0.4107363515036345, 0.3993335731422235, 0.46180086593773123, 0.8573716275918631, 0.36978842627653624, 0.08870125987737608, 0.08695172809961638, 0.059216165346970474, 0.06511951055339602, 0.05203248168878086, 0.05710676314914613, 0.050516445696334934, 0.5510388209403174])],\n",
       "       [list([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.127333688950346, 0.09234322436581963, 0.04773207405033425, 0.08591740864839292, 0.09906612386941663, 0.16755996575101473, 0.17673056657380126, 0.1784208584112109, 0.12997308290531837, 0.1401820805778844, 0.09041785030100932, 0.12312601903308593, 0.09935974560939109, 0.12811965085935792, 0.09198238812939447, 0.0945680860916482, 0.17764915372213835, 0.22743908115314923, 0.26885634741706227, 0.3870153725238347, 0.4612697089924473, 0.5609837447982309, 0.5470469974511748, 0.4291103083414414, 0.4857338787084357, 0.630141007613112, 0.8029909786073002, 0.7308936792357599, 0.5190481442369821, 0.5197319494243848, 0.45826841085916387, 0.3640694505586832, 0.285784505615126, 0.3207552479565269, 0.2989978435046817, 0.42334614783396385])],\n",
       "       [list([0.5971865183953586, 0.5564433292435058, 0.4953945013429579, 0.5121060153531903, 0.46703128334851446, 0.5485656594196442, 0.6074463097075407, 0.5910879202097776, 0.8090983613485815, 0.186351460010171, 0.08001408091485826, 0.03834329745248301, 0.05265273909216898, 0.08273772539159571, 0.10032283439999853, 0.11693753336745756, 0.11102378797238377, 0.0925475627690385, 0.10777878692534687, 0.1062528027953426, 0.0984477400057609, 0.07597467677515517, 0.15129489447183897, 0.10229806690584156, 0.08722280085247446, 0.12142111644581062, 0.13217685755224048, 0.1843515385054467, 0.20150237150845987, 0.27639555339626765, 0.26693128648397013, 0.31497225950721114, 0.352506352498062, 0.33756652268647014, 0.6574315157919947, 0.7038543642304674, 1.0, 1.0, 1.0, 0.8495909549758541, 0.6101278736473313, 0.46308194162590327, 0.5247635216102919, 0.5708065632338232, 0.3595641346752615])],\n",
       "       [list([0.49957122324584524, 0.13738902320343943, 0.09619145193774849, 0.1420543681472836, 0.11814786633522302, 0.11042533535113294, 0.1690271133199189, 0.2200620399842423, 0.5770348740149003, 0.6417233781438798, 0.5599443669341079, 0.5234211040633318, 0.5217399184880457, 0.47850819354766433, 0.5147193467642579, 0.5224537820661798, 0.48486091293326455, 0.4541352651792749, 0.3517388781102394, 0.3599730563490442, 0.40915238873734505, 0.5765210723784079, 0.5008049390998813, 0.5291218463876519, 0.4229468349148796, 0.447322106355577, 0.5071459139314123, 0.48707655906081543, 0.5188506468424849, 0.5036865867757251, 0.527040567689496, 0.530282628361924, 0.44787826763350325, 0.4968783380275465, 0.8622137678670035, 0.7303573791925752, 0.9178112918740757, 0.5692790819067397, 0.564344928073242, 0.4991313526179912, 0.3150996757533026, 0.2245302496376583, 0.2716370168175203, 0.31481023054086554, 0.4384145533330074])],\n",
       "       [list([0.39726973309854763, 0.13227540994706888, 0.1373012522079237, 0.11040893744182355, 0.10124581490325314, 0.0809540234284794, 0.18021418271615688, 0.2699571420422426, 0.5519136782102014, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9196346961232589, 0.779631937627241, 0.5472534431852222, 0.5087418939978072, 0.7239477098342818, 1.0, 1.0, 0.9423549509396504, 0.824716667975886, 0.9249996387718374, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9036948679023641, 1.0, 0.551277118189432, 0.12603259523952445, 0.14992465043020808, 0.12412401522435852, 0.09221752754796539, 0.06735071035838296, 0.07373824538243248, 0.10642761000958745, 0.20742605681299686])],\n",
       "       [list([0.3524636000793909, 0.1189408676372558, 0.08932894777833839, 0.06995825751703924, 0.05895480442999253, 0.07904911416419474, 0.14764561077184402, 0.2637785376128929, 0.4398657893823785, 0.6192072293951107, 0.543131058817427, 0.556390048702285, 0.5536721537818097, 0.6058735279932281, 0.553401358691237, 0.538908948945007, 0.4833935350846823, 0.3866683207066372, 0.2645719663711828, 0.2763478490003069, 0.37669405651918736, 0.5335523712893838, 0.5431156022915553, 0.5665764123206033, 0.49271834651187624, 0.5748668554100224, 0.5823935787702164, 0.6220142571785576, 0.5829720681263081, 0.5865678375448958, 0.5990259317243096, 0.5289954898594513, 0.5706779614282311, 0.6055181805232874, 0.6834211339142775, 0.6969118909424228, 0.34088565037294133, 0.0909385505282573, 0.08003656889643314, 0.06121182926512647, 0.052045395275079544, 0.041141127845454935, 0.03850334580989173, 0.07626893786980987, 0.1925675312912218])],\n",
       "       [list([0.24973292166922345, 0.2098044424883156, 0.1650957463339588, 0.1503615385830287, 0.12734464126612316, 0.1549422126450563, 0.18509715478748381, 0.28850777043529985, 0.2597885535480621, 0.1875449386956631, 0.16372088547701732, 0.13261015714759375, 0.11597686278750008, 0.14179065258138018, 0.10211183319811895, 0.10365508216707549, 0.11838041361570946, 0.09943906739101917, 0.09080222898988097, 0.11962625682459616, 0.11030013951939593, 0.11758971278263583, 0.1326182903617786, 0.1524597074441398, 0.14820650020588563, 0.16993775462757196, 0.16789514787773596, 0.19038788873247736, 0.17467786254236808, 0.18260358172337102, 0.19654192991170194, 0.19958023877390643, 0.21822169699801386, 0.28173695183409736, 0.40760429445183277, 0.5363422918140942, 0.3266539780258034, 0.08482033887072783, 0.044440867177208854, 0.038384073956592775, 0.023819955903356647, 0.018753379407279985, 0.025201184217226922, 0.04868598116231124, 0.240777903283087])],\n",
       "       [list([0.2601345968673159, 0.1668467574891227, 0.1049436007213672, 0.11817949448341833, 0.12289921929019113, 0.13439302007172513, 0.1542799067880318, 0.19287541668937666, 0.3677428765991658, 0.06818110305953094, 0.06310811548866796, 0.057108167466573365, 0.041467235484427656, 0.05426377807992764, 0.07178651772451278, 0.10138337806837892, 0.11859050708414498, 0.08713255467892538, 0.092356421239686, 0.12451413263633436, 0.10994844885201045, 0.07835176319136615, 0.18669170163190607, 0.08459760311442643, 0.10708033491235712, 0.09131676041759376, 0.08649598159322401, 0.10389579545989364, 0.11999027698519514, 0.10568821692126923, 0.12591815956711877, 0.17340967221086184, 0.17628705775548306, 0.23068430657928224, 0.372636902097631, 0.40795272782387637, 0.32517142978737573, 0.05426433974307129, 0.04784040368899023, 0.038626234601397115, 0.03480065866812475, 0.028007289360130784, 0.02479708958155717, 0.05364685237643263, 0.4647337936228825])],\n",
       "       [list([0.15371988821111024, 0.3467681470322637, 0.3252845073011706, 0.31853931829349325, 0.3778655058676699, 0.3858918871800163, 0.4445573863942745, 0.537859818839067, 0.47235488273408766, 0.20952419436042685, 0.21238846053762914, 0.22753389012361444, 0.288652268277272, 0.3567265863859584, 0.4166052819421178, 0.46232366105867145, 0.538038811344234, 0.5349089816113927, 0.5609548809187148, 0.5021339424330756, 0.4869759995306417, 0.4325869088701595, 0.505873349103939, 0.5668008834707374, 0.5320707636269308, 0.5295619985892293, 0.49863673351652427, 0.4812049359821405, 0.4136593469899553, 0.4252794535336132, 0.39482018794389967, 0.37722209841080434, 0.4012158977428696, 0.42590300768827366, 0.5373896891132629, 0.5294819182942871, 0.48996968206738506, 0.3806488209259888, 0.4716783529102328, 0.5121107138844526, 0.5263427128488171, 0.5210031085636276, 0.513526564030523, 0.5547730601182903, 1.0])],\n",
       "       [list([0.660789172903501, 0.6138104637649743, 0.5641698529851245, 0.5293104648197069, 0.607820186576193, 0.5994570027519842, 0.7007498804484069, 0.8976994714701854, 0.426012479049718, 0.3052742740087175, 0.3626531835472856, 0.392463064740881, 0.4945619449158336, 0.5998535161281047, 0.7240130942420413, 0.8497874966722821, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8879539870050049, 0.9671122239926047, 1.0, 1.0, 1.0, 0.9661047094825146, 0.9250356652639302, 0.8145684096892147, 0.7367413137734663, 0.6855141768481727, 0.6728130561059145, 0.6591523268148389, 0.7418179229893808, 1.0, 0.9881998007787773, 0.47358891392866587, 0.6392203700495347, 0.9004855844494732, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4417385959831208])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 196,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "32Vcd9eAEfBc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
